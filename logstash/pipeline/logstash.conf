input {
  beats {
    port => 5044
    client_inactivity_timeout => 120
  }
}

filter {
  # Parse JSON message structure
  json {
    source => "message"
    skip_on_invalid_json => true
    target => "parsed"
  }

  # Promote parsed fields to top level if parsing was successful
  if [parsed] {
    mutate {
      copy => { "[parsed]" => "[@metadata][parsed_data]" }
    }
    
    # Copy key fields from parsed data
    if [parsed][message] {
      mutate { copy => { "[parsed][message]" => "message" } }
    }
    if [parsed][levelname] {
      mutate { copy => { "[parsed][levelname]" => "levelname" } }
    }
    if [parsed][level] {
      mutate { copy => { "[parsed][level]" => "level" } }
    }
    if [parsed][correlation_id] {
      mutate { copy => { "[parsed][correlation_id]" => "[correlation][id]" } }
    }
    
    # Copy application-specific fields
    ruby {
      code => '
        parsed = event.get("parsed")
        if parsed.is_a?(Hash)
          app_fields = ["prospect_email", "subject", "classification", "research_performed", 
                       "action_id", "user_name", "channel_id", "status_code"]
          app_fields.each do |field|
            if parsed[field]
              event.set(field, parsed[field])
            end
          end
        end
      '
    }
    
    # Remove the parsed object after extracting data
    mutate { remove_field => ["parsed"] }
  }

  # Normalize log level to ECS standard
  if [levelname] and ![log][level] {
    mutate { add_field => { "[log][level]" => "%{[levelname]}" } }
  } else if [level] and ![log][level] {
    mutate { add_field => { "[log][level]" => "%{[level]}" } }
  }

  # Add service metadata
  if ![service][name] {
    mutate { add_field => { "[service][name]" => "agentic-sales-copilot" } }
  }
  if ![service][version] {
    mutate { add_field => { "[service][version]" => "0.1.0" } }
  }

  # Create conversation thread ID for email tracking
  if [prospect_email] and ![conversation][thread_id] {
    mutate {
      add_field => {
        "[conversation][thread_id]" => "%{[prospect_email]}|%{[subject]}"
      }
    }
  }

  # Rename fields to ECS-compliant structure
  mutate {
    rename => {
      "prospect_email" => "[prospect][email]"
      "subject" => "[prospect][subject]"
      "classification" => "[email][classification]"
      "research_performed" => "[email][research_performed]"
      "action_id" => "[slack][action_id]"
      "user_name" => "[slack][user]"
      "channel_id" => "[slack][channel_id]"
      "status_code" => "[http][response][status_code]"
    }
  }

  # Normalize boolean fields
  if [email][research_performed] {
    mutate {
      gsub => ["[email][research_performed]", "^(false|False)$", "false"]
      gsub => ["[email][research_performed]", "^(true|True)$", "true"]
    }
  }

  # Add timezone information
  if ![event][timezone_offset] {
    mutate { add_field => { "[event][timezone_offset]" => "+05:30" } }
  }

  # Content redaction for sensitive data
  ruby {
    code => '
      fields_to_mask = ["draft_reply","edited_text","body","conversation_history"]
      fields_to_mask.each do |f|
        if event.get(f)
          content = event.get(f).to_s
          # Store content length for analytics
          event.set("[content][#{f}][length]", content.length)
          # Redact the actual content
          event.set(f, "[REDACTED_CONTENT]")
        end
      end
    '
  }

  # Set error flag based on log level
  if [log][level] =~ /(?i)(ERROR|CRITICAL|FATAL)/ {
    mutate { add_field => { "is_error" => true } }
  } else {
    mutate { add_field => { "is_error" => false } }
  }

  # Drop health check logs to reduce noise
  if [message] =~ "GET /health" {
    drop { }
  }

  # Handle timestamp parsing
  if ![@timestamp] and [asctime] {
    date {
      match => ["asctime","ISO8601","yyyy-MM-dd HH:mm:ss,SSS"]
      target => "@timestamp"
    }
  }
  
  # Ensure we always have a timestamp
  if ![@timestamp] {
    mutate { add_field => { "@timestamp" => "%{+YYYY-MM-dd HH:mm:ss}" } }
  }

  # Add processing metadata
  mutate {
    add_field => {
      "[event][ingested]" => "%{+YYYY-MM-dd HH:mm:ss}"
      "[agent][name]" => "logstash"
      "[agent][version]" => "8.11.3"
    }
  }
}

output {
  if [is_error] {
    # If the log is an error, send it to the error index.
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "agentic-sales-copilot-error"
      retry_on_conflict => 3
      retry_max_interval => 5
      retry_initial_interval => 1
      pool_max => 1000
      pool_max_per_route => 100
      timeout => 60
      resurrect_delay => 5
      healthcheck_path => "/"
    }
  } else {
    # Otherwise, send it to the main index.
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "agentic-sales-copilot"
      retry_on_conflict => 3
      retry_max_interval => 5
      retry_initial_interval => 1
      pool_max => 1000
      pool_max_per_route => 100
      timeout => 60
      resurrect_delay => 5
      healthcheck_path => "/"
    }
  }
}